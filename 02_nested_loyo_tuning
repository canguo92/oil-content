#!/usr/bin/env Rscript
# ------------------------------------------------------------------------------
# 02_nested_loyo_tuning.R
# Climatic attribution with **nested LOYO** hyperparameter tuning (XGBoost + SHAP)
#
# Usage (example):
#   Rscript scripts/02_nested_loyo_tuning.R \
#     --input data/rapeseed_oilcontent.csv \
#     --outdir outputs_tuned \
#     --target "Oil content" \
#     --feature_range "10:108" \
#     --focus_years "2012,2016,2019,2021,2023" \
#     --seed 42 \
#     --n_tune_trials 100 \
#     --es_patience 50 \
#     --max_rounds 3000
#
# Outputs:
#   <outdir>/
#     B0_LOYO_perf_xgb.csv
#     B0_LOYO_predictions.csv
#     B0_xgb_hyperparams_selected.csv
#     B1_SHAP_long_YYYY.csv (for focus years)
#     B2_year_feature_SHAP.csv
#     B3_year_province_feature_SHAP.csv
#     B4_year_county_feature_SHAP.csv
#     plots/
#       B0_perf_RMSE_timeseries_tuned.(png|tiff)
#       B0_perf_R2_timeseries_tuned.(png|tiff)
#       B0_obs_vs_pred_facets_tuned.(png|tiff)
# ------------------------------------------------------------------------------

suppressPackageStartupMessages({
  pkgs <- c("readr","dplyr","tidyr","stringr","purrr","ggplot2","xgboost",
            "Matrix","cowplot","optparse")
  to_install <- pkgs[!pkgs %in% installed.packages()[,1]]
  if (length(to_install)) install.packages(to_install, repos = "https://cloud.r-project.org")
  library(readr); library(dplyr); library(tidyr); library(stringr); library(purrr)
  library(ggplot2); library(xgboost); library(Matrix); library(cowplot); library(optparse)
})

# ----------------------- CLI options -----------------------
option_list <- list(
  make_option("--input",        type="character", help="Input CSV path (UTF-8/GB18030/GBK tolerated)."),
  make_option("--outdir",       type="character", default="outputs_tuned", help="Output directory (default: outputs_tuned)"),
  make_option("--target",       type="character", default="Oil content", help='Target column (default: "Oil content")'),
  make_option("--feature_range",type="character", default="10:108", help='Feature column index range like "10:108"'),
  make_option("--focus_years",  type="character", default="2012,2016,2019,2021,2023", help="Comma-separated focus years for SHAP"),
  make_option("--seed",         type="integer",   default=42, help="Random seed (default: 42)"),
  make_option("--n_tune_trials",type="integer",   default=100, help="Random search iterations (default: 100)"),
  make_option("--es_patience",  type="integer",   default=50, help="Early stopping patience (default: 50)"),
  make_option("--max_rounds",   type="integer",   default=3000, help="Max boosting rounds in tuning (default: 3000)")
)
args <- parse_args(OptionParser(option_list = option_list))
stopifnot(!is.null(args$input), file.exists(args$input))

OUT_DIR   <- normalizePath(args$outdir, winslash = "/", mustWork = FALSE)
PLOTS_DIR <- file.path(OUT_DIR, "plots")
dir.create(OUT_DIR,   showWarnings = FALSE, recursive = TRUE)
dir.create(PLOTS_DIR, showWarnings = FALSE, recursive = TRUE)

target_raw_col <- args$target
feature_idx    <- {
  sp <- strsplit(args$feature_range, ":", fixed = TRUE)[[1]]
  as.integer(seq(as.integer(sp[1]), as.integer(sp[2])))
}
focus_years <- as.integer(strsplit(args$focus_years, ",")[[1]])
SEED        <- as.integer(args$seed)
N_TUNE_TRIALS <- as.integer(args$n_tune_trials)
ES_PATIENCE   <- as.integer(args$es_patience)
MAX_ROUNDS    <- as.integer(args$max_rounds)
set.seed(SEED)

# ----------------------- Utils -----------------------
robust_read_csv <- function(path){
  for (enc in c("GB18030","UTF-8","UTF-8-BOM","GBK","latin1")){
    x <- try(readr::read_csv(path, locale=readr::locale(encoding=enc), show_col_types=FALSE), silent=TRUE)
    if(!inherits(x,"try-error")) return(x)
  }
  stop("Failed to read file. Please check path or encoding: ", path)
}
nature_theme_light <- function(base_size = 11, base_family = "Arial"){
  theme_classic(base_size = base_size, base_family = base_family) %+replace%
    theme(
      legend.position = "right",
      axis.title.x = element_text(size = base_size + 1, margin = margin(6,0,0,0)),
      axis.title.y = element_text(size = base_size + 1, angle = 90, vjust = 0.5, hjust = 0.5,
                                  margin = margin(0, 2, 0, 0)),
      axis.ticks    = element_line(linewidth = 0.3),
      axis.line     = element_line(linewidth = 0.5),
      panel.grid.major = element_line(color = "grey92", linewidth = 0.3),
      panel.grid.minor = element_blank()
    )
}
save_figure_pub <- function(p, filename_base, width=7.0, height=4.2, dpi=600){
  png_path  <- file.path(PLOTS_DIR, paste0(filename_base, ".png"))
  tiff_path <- file.path(PLOTS_DIR, paste0(filename_base, ".tiff"))
  suppressWarnings(unlink(c(png_path, tiff_path), force=TRUE))
  ggplot2::ggsave(png_path, p, width=width, height=height, dpi=300)
  grDevices::tiff(filename = tiff_path, width = width, height = height,
                  units = "in", res = dpi, compression = "lzw")
  print(p); grDevices::dev.off()
}

# ----------------------- Read & prepare -----------------------
raw <- robust_read_csv(args$input)
names(raw) <- trimws(names(raw))
stopifnot(ncol(raw) >= max(feature_idx))
raw[[target_raw_col]] <- suppressWarnings(as.numeric(raw[[target_raw_col]]))
feature_cols <- names(raw)[feature_idx]
if (!"Region" %in% names(raw)) raw$Region <- raw$Province

# ----------------------- Target build -----------------------
cy_mean <- raw %>%
  group_by(Province, City, County, grow_year) %>%
  summarise(y_val = mean(.data[[target_raw_col]], na.rm=TRUE), .groups="drop")

fit_trend_1series <- function(d){
  d <- arrange(d, grow_year)
  ok <- is.finite(d$y_val) & is.finite(d$grow_year)
  out <- d; out$trend <- NA_real_; out$resid <- NA_real_
  n_ok <- sum(ok); nyrs <- dplyr::n_distinct(d$grow_year[ok])
  if (n_ok == 0) { out$method <- "no_data"; out$nyrs <- 0; return(out) }
  if (n_ok == 1) {
    mu <- d$y_val[ok]; out$trend[ok] <- mu; out$resid[ok] <- d$y_val[ok]-mu
    out$method <- "mean_only_1pt"; out$nyrs <- 1; return(out)
  }
  zt <- as.numeric(scale(d$grow_year[ok], center=TRUE, scale=TRUE))
  y  <- d$y_val[ok]
  span <- max(0.55, min(0.90, 5/nyrs + 0.35))
  pr <- try({
    suppressWarnings(predict(loess(y ~ zt, span=span, degree=1,
                                   family="symmetric",
                                   control=loess.control(surface="direct", trace.hat="approx"))))
  }, silent=TRUE)
  method <- "loess"
  if (inherits(pr, "try-error") || any(!is.finite(pr)) || nyrs < 5) {
    pr <- as.numeric(predict(lm(y ~ zt))); method <- "linear"
  }
  out$trend[ok] <- pr; out$resid[ok] <- y - pr; out$method <- method; out$nyrs <- nyrs
  out
}
cy_detr <- cy_mean %>% group_by(Province, City, County) %>%
  group_modify(~fit_trend_1series(.x)) %>% ungroup()

year_eq <- cy_detr %>% group_by(grow_year) %>%
  summarise(mu_year_eq = mean(resid, na.rm=TRUE), .groups="drop")

target <- cy_detr %>% left_join(year_eq, by="grow_year") %>%
  transmute(grow_year, Province, City, County, y = resid - mu_year_eq)

# ----------------------- Features -----------------------
feat_cy <- raw %>%
  group_by(Province, City, County, grow_year) %>%
  summarise(across(all_of(feature_cols), ~mean(suppressWarnings(as.numeric(.x)), na.rm=TRUE)), .groups="drop")

dat   <- target %>% inner_join(feat_cy, by=c("Province","City","County","grow_year"))
years <- sort(unique(dat$grow_year))

# ----------------------- Fold builders -----------------------
mk_fold_mats <- function(test_year){
  train <- dat %>% filter(grow_year != test_year)
  test  <- dat %>% filter(grow_year == test_year)
  base_train <- train %>%
    group_by(Province, City, County) %>%
    summarise(across(all_of(feature_cols), ~mean(.x, na.rm=TRUE)), .groups="drop")
  train2 <- train %>% left_join(base_train, by=c("Province","City","County"), suffix = c("", "_base"))
  test2  <- test  %>% left_join(base_train, by=c("Province","City","County"), suffix = c("", "_base"))
  for (fc in feature_cols){
    b <- paste0(fc,"_base"); g <- mean(train2[[fc]], na.rm=TRUE)
    train2[[b]][is.na(train2[[b]])] <- g; test2[[b]][is.na(test2[[b]])] <- g
    train2[[fc]] <- train2[[fc]] - train2[[b]]; test2[[fc]] <- test2[[fc]] - test2[[b]]
  }
  sds <- sapply(feature_cols, function(fc) sd(train2[[fc]], na.rm=TRUE)); sds[sds==0 | !is.finite(sds)] <- 1
  for (fc in feature_cols){
    med <- median(train2[[fc]], na.rm=TRUE); if (!is.finite(med)) med <- 0
    train2[[fc]] <- train2[[fc]]/sds[fc]; test2[[fc]] <- test2[[fc]]/sds[fc]
    train2[[fc]][!is.finite(train2[[fc]])] <- med; test2[[fc]][!is.finite(test2[[fc]])] <- med
  }
  list(train=train2, test=test2)
}

mk_fold_mats_from <- function(dat_sub, test_year){
  train <- dat_sub %>% dplyr::filter(grow_year != test_year)
  test  <- dat_sub %>% dplyr::filter(grow_year == test_year)
  base_train <- train %>%
    group_by(Province, City, County) %>%
    summarise(across(all_of(feature_cols), ~mean(.x, na.rm=TRUE)), .groups="drop")
  train2 <- train %>% left_join(base_train, by=c("Province","City","County"), suffix=c("", "_base"))
  test2  <- test  %>% left_join(base_train,  by=c("Province","City","County"), suffix=c("", "_base"))
  for (fc in feature_cols){
    b <- paste0(fc,"_base"); g <- mean(train2[[fc]], na.rm=TRUE)
    train2[[b]][is.na(train2[[b]])] <- g; test2[[b]][is.na(test2[[b]])]  <- g
    train2[[fc]] <- train2[[fc]] - train2[[b]]; test2[[fc]] <- test2[[fc]] - test2[[b]]
  }
  sds <- sapply(feature_cols, function(fc) sd(train2[[fc]], na.rm=TRUE)); sds[sds==0 | !is.finite(sds)] <- 1
  for (fc in feature_cols){
    med <- median(train2[[fc]], na.rm=TRUE); if (!is.finite(med)) med <- 0
    train2[[fc]] <- train2[[fc]]/sds[fc]; test2[[fc]] <- test2[[fc]]/sds[fc]
    train2[[fc]][!is.finite(train2[[fc]])] <- med; test2[[fc]][!is.finite(test2[[fc]])] <- med
  }
  list(train=train2, test=test2)
}

# ----------------------- Hyperparameter tuning -----------------------
sample_params <- function(){
  list(
    max_depth        = sample(2:6, 1),
    eta              = sample(c(0.03,0.05,0.07,0.10,0.15), 1),
    min_child_weight = sample(c(1,2,3,4,5,6,8), 1),
    subsample        = sample(seq(0.6,0.9,0.1), 1),
    colsample_bytree = sample(seq(0.6,0.9,0.1), 1),
    reg_alpha        = sample(c(0, 1e-3, 1e-2, 1e-1, 0.5, 1.0), 1),
    lambda           = sample(c(0,0.5,1,2,3,5), 1)
  )
}

tune_xgb_nested_loyo <- function(train_outer, n_iter, early_rounds, max_rounds, seed){
  inner_years <- sort(unique(train_outer$grow_year))
  set.seed(seed)
  rec <- vector("list", n_iter)
  for (i in seq_len(n_iter)){
    par <- sample_params()
    maes <- c(); best_iters <- c()
    for (yr_in in inner_years){
      inner <- mk_fold_mats_from(train_outer, yr_in)
      dtr <- xgb.DMatrix(as.matrix(inner$train[, feature_cols]), label=inner$train$y)
      dva <- xgb.DMatrix(as.matrix(inner$test[,  feature_cols]), label=inner$test$y)
      watch <- list(train=dtr, eval=dva)
      bst <- xgb.train(
        params=list(
          objective="reg:squarederror", eval_metric="mae", seed=seed, nthread=0,
          max_depth=par$max_depth, eta=par$eta, subsample=par$subsample,
          colsample_bytree=par$colsample_bytree, min_child_weight=par$min_child_weight,
          reg_alpha=par$reg_alpha, lambda=par$lambda
        ),
        data=dtr, nrounds=max_rounds, watchlist=watch,
        early_stopping_rounds=early_rounds, verbose=0
      )
      yhat <- predict(bst, dva)
      maes <- c(maes, mean(abs(inner$test$y - yhat)))
      bi <- tryCatch(bst$best_iteration, error=function(e) NA_integer_)
      best_iters <- c(best_iters, ifelse(is.na(bi), max_rounds, bi))
    }
    rec[[i]] <- c(par, list(mae=mean(maes), best_iter=round(stats::median(best_iters))))
  }
  tib <- dplyr::bind_rows(lapply(rec, tibble::as_tibble)) %>% dplyr::arrange(mae)
  list(best=tib[1,], all=tib)
}

# ----------------------- Train across outer folds -----------------------
all_shap_long <- list()
perfold_perf  <- list()
hp_selected   <- list()
preds_all     <- list()

for (yr in years){
  message("== Outer fold (held-out year): ", yr)
  outer <- mk_fold_mats(yr)
  train_outer <- outer$train; test_outer <- outer$test

  tuned <- tune_xgb_nested_loyo(train_outer,
                                n_iter=N_TUNE_TRIALS,
                                early_rounds=ES_PATIENCE,
                                max_rounds=MAX_ROUNDS,
                                seed=SEED)
  best <- tuned$best
  hp_selected[[as.character(yr)]] <- dplyr::mutate(best, grow_year = yr)

  dtr <- xgb.DMatrix(as.matrix(train_outer[, feature_cols]), label = train_outer$y)
  final_params <- list(
    objective="reg:squarederror", seed=SEED, nthread=0,
    max_depth=as.integer(best$max_depth),
    eta=as.numeric(best$eta),
    subsample=as.numeric(best$subsample),
    colsample_bytree=as.numeric(best$colsample_bytree),
    min_child_weight=as.numeric(best$min_child_weight),
    reg_alpha=as.numeric(best$reg_alpha),
    lambda=as.numeric(best$lambda)
  )
  nrounds_final <- as.integer(best$best_iter)
  if (!is.finite(nrounds_final) || nrounds_final <= 0) nrounds_final <- 800L
  bst <- xgb.train(params=final_params, data=dtr, nrounds=nrounds_final, verbose=0)

  dte <- xgb.DMatrix(as.matrix(test_outer[, feature_cols]), label = test_outer$y)
  pred_te <- predict(bst, dte)
  rmse <- sqrt(mean((pred_te - test_outer$y)^2))
  mae  <- mean(abs(pred_te - test_outer$y))
  r2   <- if (stats::sd(test_outer$y) > 0) stats::cor(pred_te, test_outer$y)^2 else NA_real_
  perfold_perf[[as.character(yr)]] <- tibble(grow_year=yr, RMSE=rmse, MAE=mae, R2=r2, n=nrow(test_outer))

  preds_all[[as.character(yr)]] <- tibble(
    grow_year=yr,
    Province=test_outer$Province, City=test_outer$City, County=test_outer$County,
    y_true=test_outer$y, y_pred=pred_te
  )

  if (yr %in% focus_years){
    shap <- predict(bst, dte, predcontrib = TRUE)
    colnames(shap) <- c(feature_cols, "BIAS")
    shap <- shap[, feature_cols, drop=FALSE]
    shap_long <- as.data.frame(shap) %>%
      mutate(row_id = seq_len(n())) %>%
      cbind(test_outer[, c("grow_year","Province","City","County")]) %>%
      tidyr::pivot_longer(cols = all_of(feature_cols), names_to="feature", values_to="shap_value")
    readr::write_csv(shap_long, file.path(OUT_DIR, sprintf("B1_SHAP_long_%d.csv", yr)))
    all_shap_long[[as.character(yr)]] <- shap_long
  }
}

# ----------------------- Save core tables -----------------------
perf_all <- bind_rows(perfold_perf) %>% arrange(grow_year)
readr::write_csv(perf_all, file.path(OUT_DIR, "B0_LOYO_perf_xgb.csv"))

preds_tbl <- bind_rows(preds_all)
readr::write_csv(preds_tbl, file.path(OUT_DIR, "B0_LOYO_predictions.csv"))

hp_tbl <- dplyr::bind_rows(hp_selected) %>% dplyr::select(grow_year, dplyr::everything())
readr::write_csv(hp_tbl, file.path(OUT_DIR, "B0_xgb_hyperparams_selected.csv"))

# ----------------------- Aggregate attribution tables -----------------------
if (length(all_shap_long) > 0){
  shap_all <- bind_rows(all_shap_long, .id="year_str") %>%
    mutate(grow_year = as.integer(year_str)) %>% select(-year_str)

  year_feat <- shap_all %>%
    group_by(grow_year, feature) %>%
    summarise(
      mean_shap = mean(shap_value, na.rm=TRUE),
      neg_sum   = sum(shap_value[shap_value < 0], na.rm=TRUE),
      neg_mean  = mean(shap_value[shap_value < 0], na.rm=TRUE),
      pos_sum   = sum(shap_value[shap_value > 0], na.rm=TRUE),
      n = dplyr::n(), .groups="drop"
    )
  readr::write_csv(year_feat, file.path(OUT_DIR, "B2_year_feature_SHAP.csv"))

  prov_feat <- shap_all %>%
    group_by(grow_year, Province, feature) %>%
    summarise(mean_shap = mean(shap_value, na.rm=TRUE),
              neg_sum   = sum(shap_value[shap_value < 0], na.rm=TRUE),
              n = dplyr::n(), .groups="drop")
  readr::write_csv(prov_feat, file.path(OUT_DIR, "B3_year_province_feature_SHAP.csv"))

  county_feat <- shap_all %>%
    group_by(grow_year, Province, City, County, feature) %>%
    summarise(mean_shap = mean(shap_value, na.rm=TRUE),
              neg_sum   = sum(shap_value[shap_value < 0], na.rm=TRUE),
              n = dplyr::n(), .groups="drop")
  readr::write_csv(county_feat, file.path(OUT_DIR, "B4_year_county_feature_SHAP.csv"))
}

# ----------------------- Quick perf plots -----------------------
p_rmse <- ggplot(perf_all, aes(x=grow_year, y=RMSE)) +
  geom_line(linewidth=0.7) + geom_point(size=1.6) +
  labs(x="Year", y="RMSE (p.p.)") + nature_theme_light(11)
save_figure_pub(p_rmse, "B0_perf_RMSE_timeseries_tuned", 6.8, 3.2, 600)

p_r2 <- ggplot(perf_all, aes(x=grow_year, y=R2)) +
  geom_line(linewidth=0.7) + geom_point(size=1.6) +
  scale_y_continuous(limits=c(0,1)) +
  labs(x="Year", y=expression(R^2)) + nature_theme_light(11)
save_figure_pub(p_r2, "B0_perf_R2_timeseries_tuned", 6.8, 3.2, 600)

p_scatter <- ggplot(preds_tbl, aes(x = y_pred, y = y_true)) +
  geom_abline(slope=1, intercept=0, linetype="dashed", color="grey50") +
  geom_point(alpha=0.45, size=0.8) +
  facet_wrap(~ grow_year, ncol = min(5, max(3, ceiling(sqrt(dplyr::n_distinct(preds_tbl$grow_year)))))) +
  labs(x = "Predicted anomaly (p.p.)", y = "Observed anomaly (p.p.)") +
  nature_theme_light(10)
save_figure_pub(p_scatter, "B0_obs_vs_pred_facets_tuned", 9.5, 6.5, 600)

cat("\n✅ Nested LOYO + tuning 完成。\n",
    "- 外层逐年性能：        ", file.path(OUT_DIR, "B0_LOYO_perf_xgb.csv"), "\n",
    "- 外层逐样本预测：      ", file.path(OUT_DIR, "B0_LOYO_predictions.csv"), "\n",
    "- 各外层年选中超参：    ", file.path(OUT_DIR, "B0_xgb_hyperparams_selected.csv"), "\n",
    "- SHAP 长表(关注年)：   ", file.path(OUT_DIR, "B1_SHAP_long_YYYY.csv"), "\n",
    "- 年-因子汇总：         ", file.path(OUT_DIR, "B2_year_feature_SHAP.csv"), "\n",
    "- 省-因子汇总：         ", file.path(OUT_DIR, "B3_year_province_feature_SHAP.csv"), "\n",
    "- 县-因子汇总：         ", file.path(OUT_DIR, "B4_year_county_feature_SHAP.csv"), "\n",
    "- 性能图 (RMSE/R²/散点)：", file.path(PLOTS_DIR, "B0_*_tuned.*"), "\n\n")
